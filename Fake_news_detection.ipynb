{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e197cf74",
   "metadata": {},
   "source": [
    "# Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e14dec",
   "metadata": {},
   "source": [
    "### Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ddd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True news shape: (21417, 4)\n",
      "Fake news shape: (23481, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For text preprocessing\n",
    "import re\n",
    "import string\n",
    "\n",
    "# For model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# for nlp\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Load datasets\n",
    "true_df = pd.read_csv(\"True.csv\")\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "\n",
    "print(\"True news shape:\", true_df.shape)\n",
    "print(\"Fake news shape:\", fake_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb878b4",
   "metadata": {},
   "source": [
    "### Combine, Label & Shuffle the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b5b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (44898, 5)\n",
      "                                               title  \\\n",
      "0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n",
      "1   Failed GOP Candidates Remembered In Hilarious...   \n",
      "2   Mike Penceâ€™s New DC Neighbors Are HILARIOUSLY...   \n",
      "\n",
      "                                                text subject  \\\n",
      "0  Donald Trump s White House is in chaos, and th...    News   \n",
      "1  Now that Donald Trump is the presumptive GOP n...    News   \n",
      "2  Mike Pence is a huge homophobe. He supports ex...    News   \n",
      "\n",
      "               date  label  \n",
      "0     July 21, 2017      0  \n",
      "1       May 7, 2016      0  \n",
      "2  December 3, 2016      0  \n"
     ]
    }
   ],
   "source": [
    "#Combine and label the data\n",
    "\n",
    "true_df['label'] = 1    # 1 = Real\n",
    "fake_df['label'] = 0    # 0 = Fake\n",
    "\n",
    "# Combine both\n",
    "df = pd.concat([true_df, fake_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Combined dataset shape:\", df.shape)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93422da9",
   "metadata": {},
   "source": [
    "### Clean and Prepare the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccbfdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning done.\n",
      "                                          clean_text  label\n",
      "0  break gop chairman grassley enough demand trum...      0\n",
      "1  fail gop candid rememb hilari mock eulog video...      0\n",
      "2  mike penc new dc neighbor hilari troll homopho...      0\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)  # Keep only letters\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Apply cleaning\n",
    "df['clean_text'] = df['title'] + \" \" + df['text']\n",
    "df['clean_text'] = df['clean_text'].apply(clean_text)\n",
    "\n",
    "print(\"Text cleaning done.\")\n",
    "print(df[['clean_text', 'label']].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd8078",
   "metadata": {},
   "source": [
    "### Vectorize Text & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8afefc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete!\n",
      "Accuracy: 0.9895768374164811\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5871\n",
      "           1       0.99      0.99      0.99      5354\n",
      "\n",
      "    accuracy                           0.99     11225\n",
      "   macro avg       0.99      0.99      0.99     11225\n",
      "weighted avg       0.99      0.99      0.99     11225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Model training complete!\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c67c6b7",
   "metadata": {},
   "source": [
    "### Save Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb0675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, \"fake_news_model.pkl\")\n",
    "joblib.dump(tfidf, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61dad84",
   "metadata": {},
   "source": [
    "### Streamlit app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c391a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5280ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f06041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
